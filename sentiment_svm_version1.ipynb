{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#from nltk.tokenize import MWETokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from itertools import chain\n",
    "from nltk.probability import *\n",
    "import nltk.data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train=pd.read_csv(\"Training Dataset/train_data.csv\")\n",
    "all_label=pd.read_csv(\"Training Dataset/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extractor\n",
    "* split dataset to train data and test data to train model\n",
    "* extract feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "x_train,x_test,y_train,y_test = train_test_split(all_train['text'].tolist(),all_label['label'].tolist(),test_size =0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For feature extracting, we try unigram and bigram with TF-IDF, then try unigram and bigram with word count, see the result and comopre the results, finally we find that the feature of the model with best perform is unigram and bigram with TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520000, 1984179)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unigram and bigram with TF-IDF\n",
    "# extract feature \n",
    "tfidfs = TfidfVectorizer(analyzer='word', token_pattern=\"\\w+(?:[-']\\w+)?\",ngram_range=(1, 2), lowercase=True,min_df=2)\n",
    "#get its TF-IDF vector\n",
    "x_array = tfidfs.fit_transform(x_train)  \n",
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer the label to vector\n",
    "y_array=np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model by using training dataset\n",
    "clf.fit(x_array,y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get TF-IDF vector of test data in trainingdata to get prediction and compare prediction with y_test\n",
    "x_test_array = tfidfs.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 1984179)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred=clf.predict(x_test_array)\n",
    "#get vector of y_test\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.78      0.75     25943\n",
      "           2       0.55      0.53      0.54     26012\n",
      "           3       0.56      0.52      0.54     26179\n",
      "           4       0.56      0.55      0.55     25934\n",
      "           5       0.72      0.76      0.74     25932\n",
      "\n",
      "    accuracy                           0.63    130000\n",
      "   macro avg       0.62      0.63      0.62    130000\n",
      "weighted avg       0.62      0.63      0.62    130000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see the accuracy of model\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the model to get prediction of the given test data\n",
    "#get vector\n",
    "pred_data = tfidfs.transform(test_data['text'].tolist())\n",
    "#predict\n",
    "y_pre = clf.predict(pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer format of the prediction to \n",
    "pre_test = y_pre.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the prediction to test dataframe\n",
    "pre_test = pd.Series(pre_test)\n",
    "test_data = pd.concat([test_data, pre_test], axis=1)\n",
    "test_data = test_data.rename(columns={0:'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the output result to csv\n",
    "test_data.to_csv(\"predict label.csv\", sep=',' ,index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other features\n",
    "\n",
    "After this, we have to change the features in svm model to see if there are different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram_unigram, countVector\n",
    "we use the split train data do the same step of bigram_unigram with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_all = CountVectorizer(analyzer='word', token_pattern=\"\\w+(?:[-']\\w+)?\",ngram_range=(1, 2), lowercase=True, min_df=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520000, 1984179)\n"
     ]
    }
   ],
   "source": [
    "data_count_array = vectorizer_all.fit_transform(x_train)\n",
    "print (data_count_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolinyang/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(data_count_array,y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 1984179)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcount_test_array = vectorizer_all.transform(x_test)\n",
    "xcount_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_pred = clf2.predict(xcount_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71     25943\n",
      "           2       0.50      0.48      0.49     26012\n",
      "           3       0.49      0.48      0.48     26179\n",
      "           4       0.50      0.49      0.49     25934\n",
      "           5       0.68      0.71      0.69     25932\n",
      "\n",
      "    accuracy                           0.57    130000\n",
      "   macro avg       0.57      0.57      0.57    130000\n",
      "weighted avg       0.57      0.57      0.57    130000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see the accuracy of model\n",
    "print(classification_report(y_test,y_count_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thigram_bigram, TF-IDFVector\n",
    "using the split train data do the same step of bigram_unigram with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520000, 6684484)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfs_23 = TfidfVectorizer(analyzer='word', token_pattern=\"\\w+(?:[-']\\w+)?\",ngram_range=(2, 3), lowercase=True,min_df=2)\n",
    "#get its TF-IDF vector\n",
    "x_array_23 = tfidfs_23.fit_transform(x_train)  \n",
    "x_array_23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(x_array_23,y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 6684484)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_array_23 = tfidfs_23.transform(x_test)\n",
    "x_test_array_23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred_23=clf3.predict(x_test_array_23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.79      0.75     25943\n",
      "           2       0.56      0.53      0.55     26012\n",
      "           3       0.57      0.52      0.54     26179\n",
      "           4       0.56      0.55      0.56     25934\n",
      "           5       0.71      0.76      0.73     25932\n",
      "\n",
      "    accuracy                           0.63    130000\n",
      "   macro avg       0.62      0.63      0.63    130000\n",
      "weighted avg       0.62      0.63      0.63    130000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see the accuracy of model\n",
    "print(classification_report(y_test,y_pred_23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thigram_bigram, CountVector\n",
    "using the split train data do the same step of bigram_unigram with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_all2 = CountVectorizer(analyzer='word', token_pattern=\"\\w+(?:[-']\\w+)?\",ngram_range=(2, 3), lowercase=True, min_df=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520000, 3896389)\n"
     ]
    }
   ],
   "source": [
    "data_count_array_23 = vectorizer_all2.fit_transform(x_train)\n",
    "print (data_count_array_23.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolinyang/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(data_count_array_23,y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 3896389)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcount_test_array_23 = vectorizer_all2.transform(x_test)\n",
    "xcount_test_array_23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_pred_23 = clf4.predict(xcount_test_array_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.72      0.72     26221\n",
      "           2       0.52      0.49      0.50     26051\n",
      "           3       0.50      0.48      0.49     25996\n",
      "           4       0.50      0.50      0.50     25649\n",
      "           5       0.68      0.73      0.70     26083\n",
      "\n",
      "    accuracy                           0.58    130000\n",
      "   macro avg       0.58      0.58      0.58    130000\n",
      "weighted avg       0.58      0.58      0.58    130000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see the accuracy of model\n",
    "print(classification_report(y_test,y_count_pred_23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
